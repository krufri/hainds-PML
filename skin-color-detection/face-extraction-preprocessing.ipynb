{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this file is used to preprocess the training/test data images and is not used in the final app\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.cluster import KMeans\n",
    "from collections import Counter\n",
    "import imutils\n",
    "import pprint\n",
    "from matplotlib import pyplot as plt\n",
    "import glob\n",
    "import shutil\n",
    "import os\n",
    "from face_toolbox_keras.models.detector import face_detector\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "from face_toolbox_keras.models.parser import face_parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(im, max_size=450):\n",
    "    if np.max(im.shape) > max_size:\n",
    "        ratio = max_size / np.max(im.shape)\n",
    "        print(f\"Resize image to ({str(int(im.shape[1]*ratio))}, {str(int(im.shape[0]*ratio))}).\")\n",
    "        return cv2.resize(im, (0,0), fx=ratio, fy=ratio)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resize image to (311, 450).\n",
      "Resize image to (330, 450).\n",
      "Resize image to (316, 450).\n"
     ]
    }
   ],
   "source": [
    "src_dir = r\"test_data/facesTestImages\"\n",
    "dst_dir = r\"test_data/facesTestImagesProcessed\"\n",
    "fd = face_detector.FaceAlignmentDetector(\n",
    "    lmd_weights_path=\"./models/detector/FAN/2DFAN-4_keras.h5\"\n",
    ")\n",
    "prs = face_parser.FaceParser()\n",
    "\n",
    "for image in  glob.iglob(os.path.join(src_dir, \"*.jpg\")):\n",
    "    imageName = image.rsplit('\\\\', 1)[1]\n",
    "    currentImage = cv2.imread(image)[..., ::-1]\n",
    "    resizedImage = resize_image(currentImage)\n",
    "    bboxes = fd.detect_face(resizedImage, with_landmarks=False)\n",
    "    assert len(bboxes) > 0, \"No face detected.\"\n",
    "    x0, y0, x1, y1, score = bboxes[0]\n",
    "    x0, y0, x1, y1 = map(int, [x0, y0, x1, y1])\n",
    "    face = resizedImage[x0:x1, y0:y1, :]\n",
    "    mask = prs.parse_face(face)\n",
    "    for i in range(len(mask)):\n",
    "        for j in range(len(mask[0])):\n",
    "            for k in range(len(mask[0][0])):\n",
    "                if mask[i][j][k] != 1:\n",
    "                    mask[i][j][k] = 0\n",
    "    newmask = mask[0]\n",
    "    newImg = cv2.bitwise_and(face,face,mask=newmask)\n",
    "    resizedFace = cv2.resize(newImg, (250, 187), interpolation= cv2.INTER_LINEAR)\n",
    "    os.chdir(dst_dir)\n",
    "    cv2.imwrite( imageName, cv2.cvtColor(resizedFace, cv2.COLOR_RGB2BGR))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6343f46f8df3be7166a2d52bb819e52e68d49fa6298932d86815154baa3d97af"
  },
  "kernelspec": {
   "display_name": "Python 3.9.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
